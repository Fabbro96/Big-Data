\documentclass[12pt,a4paper]{article}
\usepackage{mwe}
\usepackage{imakeidx}
\makeindex
\usepackage{hyperref}
\usepackage{xcolor}

\begin{document}
    \begin{titlepage}
    	\centering
        {\textsc{Universitá degli studi di Verona} \par}
        \par\vspace{1cm}
    	\includegraphics[width=0.15\textwidth]{logoUni.png}
        \par
    	\vspace{1cm}
    	{\Large \textsc{Progetto di Big Data}\par}
    	\vspace{1cm}
        {\Large \textsc{Wikipedia inverted index}\par}
    	\vspace{5cm}
    	{\Large\itshape Fabrizio Bassan VR479096\par}
    	\vfill
    	{\large Aprile 2023 \par}
    \end{titlepage}
    
    \tableofcontents
    \newpage
    \section{Introduzione}
    Richiesta del progetto: "L’output deve contenere, per ogni parola, la lista di pagine di wikipedia che contengono quella parola".
    Divideremo, quindi, in 3 parti il progetto: una fase di processing, una parte per la gestione dell'inverted index e la fase finale, la creazione dei grafici.
    Utilizzeremo principalmente 4 librerie: pyspark, lxml, pandas, matplotlib.
    Ce ne sono altre ma sono tendenzialmente di contorno a queste che sono praticamente essenziali.
    \newline
    Ovviamente ci sará una prima fase per controllare se il file (con estensione xml) esiste, in quel caso si andrá avanti, altrimenti verrá generato un errore che bloccherá l'esecuzione.
    \section{Processing}
    La fase di processing si suddivide in piú parti.
    \subsection{Metodi}
    Qui abbiamo utilizzato due metodi (removeNestedParentheses e cleanUp) per pulire il piú possibile il file che verrá generato a partire dal file.xml in quanto questo é scritto in formato \textit{WikiText}, un linguaggio di MarkUp particolare usato da wikipedia. Arriviamo ora alle stop words. Cosa sono le stop words? Chiedendo aiuto ad internet, la sua definizione risulta questa: \textit{sono quelle parole che, per la loro alta frequenza in una lingua, sono di solito ritenute poco significative dai motori di ricerca, che le ignorano.}. Nel nostro caso, prendiamo le stop words inglesi, come ad esempio verbi ausiliari (is, are, am, ecc.), congiunzioni (but, and, ecc.) e cosí via.
    \subsection{Analisi del file}
    Finalmente arriviamo alla parte piú importante: il processamento del file.
    \newline
    Creo due file CSV (cosí mi é piú semplice analizzarli piú avanti), con due header ciascuno: index, che é la colonna comune fra i due, e altri, complessivamente, due campi ossia \textbf{text} e \textbf{title}. Molto importante sará l'utilizzo del comando \textit{\textcolor{blue}{elem.clear()}} che ci permetterá di non sovraccaricare la memoria primaria scrivendo quindi ogni volta che un tag \textcolor{red}{text} oppure \textcolor{red}{title} viene trovato, una riga in uno dei due file csv creati all'inizio della cella.
    \newline
    Ho anche impostato un contatore formattato appositamente che stamperá la percentuale di completamento dell'operazione.
    \section{Inverted Index}
    Qui si andrá ad utilizzare principalmente la libreria PySpark. 
    \newline
    Dopo aver creato una SparkSession, andró a unire i due file csv precedentemente creati utilizzando la colonna in comune: \textit{index}. Ne uscirá quindi un file unico \textit{\textcolor{blue}{rawMerged.csv}} contenente, per ogni titolo, tutte le parole che aveva all'interno della sua pagina. 
    \newline
    Successivamente si andrá a creare un altro file \textit{\textcolor{blue}{countedWords.csv}} che conterrá 3 colonne: il titolo della pagina, la parola singola utilizzata ed un counter per tener conto di quante volte quella parola é stata utilizzata in quella pagina.
    \newline
    Da qui, ho generato un altro file \textit{\textcolor{blue}{singleWordCounted.csv}} che avrá due sole colonne che indicheranno la parola ed il numero di occorrenze.
    \newline
    Riprendendo \textcolor{purple}{countedWords.csv} vado ad eliminare la colonna \textit{count} cosí da creare un file \textit{\textcolor{blue}{finalFileToAnalyze.csv}} per lettere tutte le parole presenti e salvarle in un set (per eliminare tutti i doppioni) e fare un casting di questo set a lista in modo da renderlo piú flessibile e comodo.
    \newline
    Ci servirá per creare (finalmente) il nostro file finale: \textit{\textcolor{blue}{results.csv}} che avrá due colonne: word e titles (che é la lista dei titoli), filtrando le parole in modo da evitare doppioni, usando la lista precedentemente creata e scrivendo, sempre in un file csv, riga per riga.
    \newline
    Poi creeró altri tre files, \textit{\textcolor{brown}{initialLetter.csv}} (due colonne, char e occurence), \textit{\textcolor{brown}{titlesSize.csv}} (due colonne, word e list\_size) e \textit{\textcolor{brown}{occurences.csv}} (list\_size e occurences che contiene la frequenza del numero di parole) che ci serviranno per la generazione dei grafici.
    \newline Infine
    \newline Ho utilizzato parecchio, ovviamente, la libreria PySpark in quanto ci é tornata molto utile per le operazioni complesse sui files csv (vedi ad esempio i groupBy) mentre per le operazioni piú semplici ho preferito usare pandas.
    \newpage
    \section{Grafici}
    Le librerie che ho utilizzato di piú qui sono principalmente pandas per l'analisi dei csv e matplotlib per la generazione dei grafici.
    Ne ho creati 5:
    \begin{itemize}
        \item Parole piú utilizzate: il primo grafico che mi é venuto in mente, anche quello piú effettivamente semplice. É un semplice grafico a barre generato con l'ausilio di \textit{\textcolor{blue}{singleWordCounted.csv}}. Rappresentata nell'asse x la parola e nell'asse y le occorrenze di quella parola.
        Per rendere il tutto piú "pulito ed ordinato" ho preso soltanto le prime 10, ossia quelle con i valori maggiori.
        \item Parole presenti in piú titoli: su queste ci ho pensato un po' di piú, come dice il titolo viene mostrato un grafico che indica le stesse cose sopra ma, in soldoni, le parole singole piú utilizzate, senza doppioni. Infatti i valori sono di molto inferiori. Qui ho utilizzato il file \textit{\textcolor{blue}{titlesSize.csv}}.
        \item Ho anche sfruttato il file \textit{\textcolor{brown}{occurrences.csv}} per generare i due grafici successivi: entrambi raggruppano i titoli che contengono lo stesso numero di parole solo che nel primo verrá generato in base a circa 50 valori, nel secondo, che risulta piú dettagliato, andremo a crearlo basandoci sui 5 valori maggiori.
        Mi spiego meglio: i titoli che contengono una parola sono quasi di 1 milione e mezzo.
        \item Nell'ultimo grafico ho unito due tipologie di grafici: lo scatter ed il plot (con il solo scatter veniva troppo confusionario), invece cosí (anche se il risultato sembra uno di quei giochini in stile "unisci i puntini) é piú ordinato e capibile. Ho usato due colori diversi in modo da risaltare l'unione fra i due.
        Questa volta il file che ci ha aiutato nella creazione di quest'ultimo grafico é stato \textit{\textcolor{brown}{initialLetter.csv}}.
        \end{itemize}
    \section{Finale}
    Alla fine fermo l'instanza di spark e chiedo se i files creati precedentemente creati (tutti con estensione csv) volessero esser eliminati. Avrei voluto andare a chiedere singolarmente, file per file, se volesse esser cancellato oppure no ma mi é sembrata una scelta fin troppo lunga e dispersiva. Ho usato la libreria \textit{os} in modo da eseguire automaticamente l'azione.
\end{document}