{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: mwparserfromhell in /home/fabbro/.local/lib/python3.10/site-packages (0.6.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: lxml in /home/fabbro/.local/lib/python3.10/site-packages (4.9.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: pyspark in /home/fabbro/.local/lib/python3.10/site-packages (3.3.2)\n",
      "Requirement already satisfied: py4j==0.10.9.5 in /home/fabbro/.local/lib/python3.10/site-packages (from pyspark) (0.10.9.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: nltk in /home/fabbro/.local/lib/python3.10/site-packages (3.8.1)\n",
      "Requirement already satisfied: click in /home/fabbro/.local/lib/python3.10/site-packages (from nltk) (8.1.3)\n",
      "Requirement already satisfied: regex>=2021.8.3 in /home/fabbro/.local/lib/python3.10/site-packages (from nltk) (2022.10.31)\n",
      "Requirement already satisfied: tqdm in /home/fabbro/.local/lib/python3.10/site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: joblib in /home/fabbro/.local/lib/python3.10/site-packages (from nltk) (1.2.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Requirement already satisfied: numba in /home/fabbro/.local/lib/python3.10/site-packages (0.56.4)\n",
      "Requirement already satisfied: llvmlite<0.40,>=0.39.0dev0 in /home/fabbro/.local/lib/python3.10/site-packages (from numba) (0.39.1)\n",
      "Requirement already satisfied: setuptools in /home/fabbro/.local/lib/python3.10/site-packages (from numba) (65.6.3)\n",
      "Requirement already satisfied: numpy<1.24,>=1.18 in /home/fabbro/.local/lib/python3.10/site-packages (from numba) (1.23.5)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install mwparserfromhell\n",
    "%pip install lxml\n",
    "%pip install pyspark\n",
    "%pip install nltk\n",
    "%pip install numba"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import nltk\n",
    "import re\n",
    "import os.path\n",
    "import shutil\n",
    "import mwparserfromhell\n",
    "from lxml import etree\n",
    "from nltk.corpus import stopwords\n",
    "from tqdm import tqdm\n",
    "from alive_progress import alive_bar\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import explode, lower, split, count"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Static things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/fabbro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "stop_words = set(stopwords.words(\"english\"))\n",
    "header = ['Index', 'Text']\n",
    "lista = []\n",
    "\n",
    "#Testando una la alive progress bar\n",
    "num_rows = 356900000\n",
    "counter = 0\n",
    "increment = 100000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dynamic things"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: ''",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39melif\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(\u001b[39m\"\u001b[39m\u001b[39m/home/fabbro/Documents/Big-Data/file.xml\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[1;32m      9\u001b[0m     file_xml \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m/home/fabbro/Documents/Big-Data/file.xml\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m---> 11\u001b[0m \u001b[39mfor\u001b[39;00m event, elem \u001b[39min\u001b[39;00m etree\u001b[39m.\u001b[39;49miterparse(file_xml):\n\u001b[1;32m     12\u001b[0m     text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m     13\u001b[0m     title\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32msrc/lxml/iterparse.pxi:79\u001b[0m, in \u001b[0;36mlxml.etree.iterparse.__init__\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: ''"
     ]
    }
   ],
   "source": [
    "f= open(\"file.csv\", \"w+\")\n",
    "writer = csv.writer(f)\n",
    "writer.writerow(header)\n",
    "totalCount = 0\n",
    "file_xml= ''\n",
    "if os.path.isfile(\"/home/fabbro/Documents/Cartella/fileWiki.xml\"):\n",
    "    file_xml = \"/home/fabbro/Documents/Cartella/fileWiki.xml\"\n",
    "elif os.path.isfile(\"/home/fabbro/Documents/Big-Data/file.xml\"):\n",
    "    file_xml = \"/home/fabbro/Documents/Big-Data/file.xml\"\n",
    "\n",
    "for event, elem in etree.iterparse(file_xml):\n",
    "    text = \"\"\n",
    "    title=\"\"\n",
    "    if('title' in str(elem.tag)):\n",
    "        #title_list.append(elem.text)\n",
    "        #titoliTxt.write(elem.text+\"\\n\")\n",
    "        if(elem.text is not None):\n",
    "            title = elem.text.lower()\n",
    "            title = \" \".join([word for word in title.split() if word not in stop_words])\n",
    "            lista.append(title)\n",
    "            #print(title)\n",
    "\n",
    "    if('text' in str(elem.tag)):\n",
    "        #text_list.append(elem.text)\n",
    "        if(elem.text is not None):\n",
    "            text = elem.text.lower()\n",
    "            text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "            lista.append(text)\n",
    "            #print(text)\n",
    "            \n",
    "    if len(lista) == 2:\n",
    "        writer.writerow([lista[0], lista[1]])\n",
    "        lista=[]\n",
    "    elem.clear()\n",
    "    totalCount += 1\n",
    "    if totalCount > 1 and (totalCount % 100000) == 0:\n",
    "            print(\"{:,}\".format(totalCount)+\" rows written of 356,900,000\", end=\"\\r\") \n",
    "            pbar.update(1)\n",
    "    \n",
    "    \"\"\" if totalCount > 1 and (totalCount % 356900000000) == 0:\n",
    "            print(\"{:,}\".format(totalCount)+\"%\")\n",
    "            pbar.update(1) \"\"\"\n",
    "    '''if totalCount > 35000:\n",
    "        break'''\n",
    "f.close()\n",
    "pbar.close()\n",
    "print(\"-------------------------------------------DONE------------------------------------------------------\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Removing the sections titles and break if we are at the end of the part of the page we want to parse (some pages have a lot of sections that we don't want to parse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "I has a template! See it or no? and puppy New York also has public transportation. New York is a state in the Northeastern United States and is the 27th-most extensive, fourth-most populous, and seventh-most densely populated U.S. state. New York is bordered by New Jersey and Pennsylvania to the south and Connecticut, Massachusetts, and Vermont to the east. The state has a maritime border in the Atlantic Ocean with Rhode Island, east of Long Island, as well as an international border with the Canadian provinces of Quebec to the north and Ontario to the west and north. The state of New York, with an estimated 19.8 million residents in 2015, is often referred to as New York State to distinguish it from New York City, the state's most populous city and its economic hub. With an estimated population of 8.55 million in 2015, New York City is the most populous city in the United States and the premier gateway for legal immigration to the United States. The New York City Metropolitan Area is one of the most populous urban agglomerations in the world. New York City is a global city, exerting a significant impact upon commerce, finance, media, art, fashion, research, technology, education, and entertainment, its fast pace defining the term New York minute. The home of the United Nations Headquarters, New York City is an important center for international diplomacy and has been described as the cultural and financial capital of the world, as well as the world's most economically powerful city. New York City makes up over 40% of the population of New York State. Two-thirds of the state's population lives in the New York City Metropolitan Area, and nearly 40% live on Long Island. Both the state and New York City were named for the 17th century Duke of York, future King James II of England. The next four most populous cities in the state are Buffalo, Rochester, Yonkers, and Syracuse, while the state capital is Albany. The earliest Europeans in New York were French colonists and Jesuit missionaries who arrived southward from settlements at Montreal for trade and proselytizing. New York had been inhabited by tribes of Algonquian and Iroquoian-speaking Native Americans for several hundred years by the time Dutch settlers moved into the region in the early 17th century. In 1609, the region was first claimed by Henry Hudson for the Dutch, who built Fort Nassau in 1614 at the confluence of the Hudson and Mohawk rivers, where the present-day capital of Albany later developed. The Dutch soon also settled New Amsterdam and parts of the Hudson Valley, establishing the colony of New Netherland, a multicultural community from its earliest days and a center of trade and immigration. The British annexed the colony from the Dutch in 1664. The borders of the British colony, the Province of New York, were similar to those of the present-day state. Many landmarks in New York are well known to both international and domestic visitors, with New York State hosting four of the world's ten most-visited tourist attractions in 2013: Times Square, Central Park, Niagara Falls (shared with Ontario), and Grand Central Terminal. New York is home to the Statue of Liberty, a symbol of the United States and its ideals of freedom, democracy, and opportunity. In the 21st century, New York has emerged as a global node of creativity and entrepreneurship, social tolerance, and environmental sustainability. New York's higher education network comprises approximately 200 colleges and universities, including Columbia University, Cornell University, New York University, and Rockefeller University, which have been ranked among the top 35 in the world. In 1524, Giovanni da Verrazzano, an Italian explorer in the service of the French crown, explored the Atlantic coast of North America between the Carolinas and Newfoundland, including New York Harbor and Narragansett Bay. On April 17, 1524 Verrazanno entered New York Bay, by way of the Strait now called the Narrows into the northern bay which he named Santa Margherita, in honour of the King of France's sister. Verrazzano described it as \"a vast coastline with a deep delta in which every kind of ship could pass\" and he adds: \"that it extends inland for a league and opens up to form a beautiful lake. This vast sheet of water swarmed with native boats\". He landed on the tip of Manhattan and perhaps on the furthest point of Long Island. Verrazanno's stay in this place was interrupted by a storm which pushed him north towards Martha's Vineyard. In 1540 French traders from New France built a chateau on Castle Island, within present-day Albany; due to flooding, it was abandoned the next year. In 1614, the Dutch under the command of Hendrick Corstiaensen, rebuilt the French chateau, which they called Fort Nassau. Fort Nassau was the first Dutch settlement in North America, and was located along the Hudson River, also within present-day Albany. The small fort served as a trading post and warehouse. Located on the Hudson River flood plain, the rudimentary \"fort\" was washed away by flooding in 1617, and abandoned for good after Fort Orange (New Netherland) was built nearby in 1623. Henry Hudson's 1609 voyage marked the beginning of European involvement with the area. Sailing for the Dutch East India Company and looking for a passage to Asia, he entered the Upper New York Bay on September 11 of that year. Word of his findings encouraged Dutch merchants to explore the coast in search for profitable fur trading with local Native American tribes. During the 17th century, Dutch trading posts established for the trade of pelts from the Lenape, Iroquois, and other tribes were founded in the colony of New Netherland. The first of these trading posts were Fort Nassau (1614, near present-day Albany); Fort Orange (1624, on the Hudson River just south of the current city of Albany and created to replace Fort Nassau), developing into settlement Beverwijck (1647), and into what became Albany; Fort Amsterdam (1625, to develop into the town New Amsterdam which is present-day New York City); and Esopus, (1653, now Kingston). The success of the patroonship of Rensselaerswyck (1630), which surrounded Albany and lasted until the mid-19th century, was also a key factor in the early success of the colony. The English captured the colony during the Second Anglo-Dutch War and governed it as the Province of New York. The city of New York was recaptured by the Dutch in 1673 during the Third Anglo-Dutch War (1672–1674) and renamed New Orange. It was returned to the English under the terms of the Treaty of Westminster a year later.\n"
     ]
    }
   ],
   "source": [
    "def removeNestedParentheses(s):\n",
    "    lines = s.split('\\n')\n",
    "    print(len(lines))\n",
    "    ret = []\n",
    "    for line in lines:\n",
    "        curr_line = ''\n",
    "        skip = 0\n",
    "        for i in line:\n",
    "            if i == '[':\n",
    "                skip += 1\n",
    "            elif i == ']'and skip > 0:\n",
    "                skip -= 1\n",
    "            elif skip == 0:\n",
    "                curr_line += i\n",
    "        ret.append(curr_line+\"\\n\")\n",
    "    return '\\n'.join(ret)\n",
    "\n",
    "text = '''\n",
    "I has a template! {{foo|bar|baz|eggs=spam}} See it <nowiki>or no<!-- revealed --></nowiki>[[File:wiki.png|thumb|Wikipedia logo]]? [[fox]] and [[dog|puppy]] New York also has [[public transport|public transportation]].\n",
    "\n",
    "\n",
    "New York is a state in the Northeastern United States and is the 27th-most extensive, fourth-most populous, and seventh-most densely populated U.S. state. New York is bordered by New Jersey and Pennsylvania to the south and Connecticut, Massachusetts, and Vermont to the east. The state has a maritime border in the Atlantic Ocean with Rhode Island, east of Long Island, as well as an international border with the Canadian provinces of Quebec to the north and Ontario to the west and north. The state of New York, with an estimated 19.8 million residents in 2015, is often referred to as New York State to distinguish it from New York City, the state's most populous city and its economic hub.\n",
    "With an estimated population of 8.55 million in 2015, New York City is the most populous city in the United States and the premier gateway for legal immigration to the United States. The New York City Metropolitan Area is one of the most populous urban agglomerations in the world. New York City is a global city, exerting a significant impact upon commerce, finance, media, art, fashion, research, technology, education, and entertainment, its fast pace defining the term New York minute. The home of the United Nations Headquarters, New York City is an important center for international diplomacy and has been described as the cultural and financial capital of the world, as well as the world's most economically powerful city. New York City makes up over 40% of the population of New York State. Two-thirds of the state's population lives in the New York City Metropolitan Area, and nearly 40% live on Long Island. Both the state and New York City were named for the 17th century Duke of York, future King James II of England. The next four most populous cities in the state are Buffalo, Rochester, Yonkers, and Syracuse, while the state capital is Albany.\n",
    "The earliest Europeans in New York were French colonists and Jesuit missionaries who arrived southward from settlements at Montreal for trade and proselytizing. New York had been inhabited by tribes of Algonquian and Iroquoian-speaking Native Americans for several hundred years by the time Dutch settlers moved into the region in the early 17th century. In 1609, the region was first claimed by Henry Hudson for the Dutch, who built Fort Nassau in 1614 at the confluence of the Hudson and Mohawk rivers, where the present-day capital of Albany later developed. The Dutch soon also settled New Amsterdam and parts of the Hudson Valley, establishing the colony of New Netherland, a multicultural community from its earliest days and a center of trade and immigration. The British annexed the colony from the Dutch in 1664. The borders of the British colony, the Province of New York, were similar to those of the present-day state.\n",
    "Many landmarks in New York are well known to both international and domestic visitors, with New York State hosting four of the world's ten most-visited tourist attractions in 2013: Times Square, Central Park, Niagara Falls (shared with Ontario), and Grand Central Terminal. New York is home to the Statue of Liberty, a symbol of the United States and its ideals of freedom, democracy, and opportunity. In the 21st century, New York has emerged as a global node of creativity and entrepreneurship, social tolerance, and environmental sustainability. New York's higher education network comprises approximately 200 colleges and universities, including Columbia University, Cornell University, New York University, and Rockefeller University, which have been ranked among the top 35 in the world.\n",
    "\n",
    "\n",
    "== History ==\n",
    "\n",
    "\n",
    "=== 16th century ===\n",
    "In 1524, Giovanni da Verrazzano, an Italian explorer in the service of the French crown, explored the Atlantic coast of North America between the Carolinas and Newfoundland, including New York Harbor and Narragansett Bay. On April 17, 1524 Verrazanno entered New York Bay, by way of the Strait now called the Narrows into the northern bay which he named Santa Margherita, in honour of the King of France's sister. Verrazzano described it as \"a vast coastline with a deep delta in which every kind of ship could pass\" and he adds: \"that it extends inland for a league and opens up to form a beautiful lake. This vast sheet of water swarmed with native boats\". He landed on the tip of Manhattan and perhaps on the furthest point of Long Island. Verrazanno's stay in this place was interrupted by a storm which pushed him north towards Martha's Vineyard.\n",
    "In 1540 French traders from New France built a chateau on Castle Island, within present-day Albany; due to flooding, it was abandoned the next year. In 1614, the Dutch under the command of Hendrick Corstiaensen, rebuilt the French chateau, which they called Fort Nassau. Fort Nassau was the first Dutch settlement in North America, and was located along the Hudson River, also within present-day Albany. The small fort served as a trading post and warehouse. Located on the Hudson River flood plain, the rudimentary \"fort\" was washed away by flooding in 1617, and abandoned for good after Fort Orange (New Netherland) was built nearby in 1623.\n",
    "\n",
    "\n",
    "=== 17th century ===\n",
    "\n",
    "Henry Hudson's 1609 voyage marked the beginning of European involvement with the area. Sailing for the Dutch East India Company and looking for a passage to Asia, he entered the Upper New York Bay on September 11 of that year. Word of his findings encouraged Dutch merchants to explore the coast in search for profitable fur trading with local Native American tribes.\n",
    "During the 17th century, Dutch trading posts established for the trade of pelts from the Lenape, Iroquois, and other tribes were founded in the colony of New Netherland. The first of these trading posts were Fort Nassau (1614, near present-day Albany); Fort Orange (1624, on the Hudson River just south of the current city of Albany and created to replace Fort Nassau), developing into settlement Beverwijck (1647), and into what became Albany; Fort Amsterdam (1625, to develop into the town New Amsterdam which is present-day New York City); and Esopus, (1653, now Kingston). The success of the patroonship of Rensselaerswyck (1630), which surrounded Albany and lasted until the mid-19th century, was also a key factor in the early success of the colony. The English captured the colony during the Second Anglo-Dutch War and governed it as the Province of New York. The city of New York was recaptured by the Dutch in 1673 during the Third Anglo-Dutch War (1672–1674) and renamed New Orange. It was returned to the English under the terms of the Treaty of Westminster a year later.\n",
    "\n",
    "\n",
    "== References ==\n",
    "\n",
    "\n",
    "== Further reading ==\n",
    "\n",
    "French, John Homer (1860). Historical and statistical gazetteer of New York State. Syracuse, New York: R. Pearsall Smith. OCLC 224691273. (Full text via Google Books.)\n",
    "New York State Historical Association (1940). New York: A Guide to the Empire State. New York City: Oxford University Press. ISBN 978-1-60354-031-5. OCLC 504264143. (Full text via Google Books.)\n",
    "\n",
    "\n",
    "== External links ==\n",
    "New York at DMOZ\n",
    " Geographic data related to New York at OpenStreetMap'''\n",
    "\n",
    "\n",
    "\n",
    "section_title_re = re.compile(\"^=+\\s+.*\\s+=+$\")\n",
    "content = ''\n",
    "skip = False\n",
    "\n",
    "for l in text.splitlines():\n",
    "    line = l.strip()\n",
    "    if \"= references =\" in line.lower():\n",
    "        skip = True  # replace with break if this is the last section\n",
    "        break\n",
    "    if \"= further reading =\" in line.lower():\n",
    "        skip = True  # replace with break if this is the last section\n",
    "        continue\n",
    "    if section_title_re.match(line):\n",
    "        skip = False\n",
    "        continue\n",
    "    if skip:\n",
    "        continue\n",
    "    content+=line+'\\n'\n",
    "    \n",
    "\"\"\" for x in content:\n",
    "    if x != \"\":\n",
    "        print(x.lower()+\"\\n\")\n",
    " \"\"\"\n",
    " \n",
    "withoutPipeLinks = (re.sub(r\"\\[\\[[^|\\]]*\\|([^|\\]]*)]]\", r\"\\1\", content, flags=re.S))\n",
    "withOutComments= re.sub('<!--.*?-->', '', withoutPipeLinks, flags=re.S)\n",
    "cleaned= re.sub('<.*?>', '', withOutComments, flags=re.S)\n",
    "testoPulito = removeNestedParentheses(cleaned)\n",
    "wikicode = mwparserfromhell.parse(testoPulito)\n",
    "templates = wikicode.filter_templates()\n",
    "text = \" \".join([testo for testo in testoPulito.split() if testo not in templates])\n",
    "print(text)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----\n",
    "Idee per andare avanti:\n",
    "1. Eliminare prima le doppie graffe (di apertura e chiusura) eliminando il loro contenuto\n",
    "\n",
    "2. Capire come gestire il comportamento delle stringhe tipo `[[political movement|movement]]` dove l'importante è contenuto dopo la pipe.\n",
    "\n",
    "3. Eliminare qualsiasi segno di punteggiature (creando una lista di tutti i simboli di punteggiatura) andandoli a rimpiazzare con un singolo spazio in modo che ogni parola sia distanziata effettivamente dall'altra\n",
    "\n",
    "4. Effettuare un replace di tutti gli spazi (ce ne serve solo uno tra una parola e l'altra, non di più), basta usare la classe `re`\n",
    "\n",
    "5. Ora che abbiamo tutto l'occorrente, salvare su un file csv ed effettuare l'analisi con _pyspark_\n",
    "\n",
    "----\n",
    "_Domande al professore:_\n",
    "\n",
    "__Risposte da scrivere nella documentazione finale__\n",
    "\n",
    "1. I numeri sono visti come parole? Sì\n",
    "\n",
    "2. Teniamo conto dei titoli dei sotto-capitoli? No\n",
    "\n",
    "3. Teniamo conto delle ''references''? No\n",
    "\n",
    "4. Posso usare PonyORM?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNestedParentheses(s):\n",
    "    lines = s.split('\\n')\n",
    "    ret = []\n",
    "    for line in lines:\n",
    "        curr_line = ''\n",
    "        skip = 0\n",
    "        for i in line:\n",
    "            if i == '[' or i == '{' :\n",
    "                skip += 1\n",
    "            elif (i == ']' or i == '}' ) and skip > 0:\n",
    "                skip -= 1\n",
    "            elif skip == 0:\n",
    "                curr_line += i\n",
    "        ret.append(curr_line+\"\\n\")\n",
    "    return '\\n'.join(ret)\n",
    "\n",
    "def cleanUp(text):\n",
    "    section_title_re = re.compile(\"^=+\\s+.*\\s+=+$\")\n",
    "    content = ''\n",
    "    skip = False\n",
    "\n",
    "    for l in text.splitlines():\n",
    "        line = l.strip()\n",
    "        if \"= references =\" in line.lower():\n",
    "            skip = True  # replace with break if this is the last section\n",
    "            break\n",
    "        if \"= further reading =\" in line.lower():\n",
    "            skip = True  # replace with break if this is the last section\n",
    "            continue\n",
    "        if section_title_re.match(line):\n",
    "            skip = False\n",
    "            continue\n",
    "        if skip:\n",
    "            continue\n",
    "        content+=line+'\\n'\n",
    "        \n",
    "    \"\"\" for x in content:\n",
    "        if x != \"\":\n",
    "            print(x.lower()+\"\\n\")\n",
    "    \"\"\"\n",
    "    \n",
    "    withoutPipeLinks = (re.sub(r\"\\[\\[[^|\\]]*\\|([^|\\]]*)]]\", r\"\\1\", content, flags=re.S))\n",
    "    withOutComments= re.sub('<!--.*?-->', '', withoutPipeLinks, flags=re.S)\n",
    "    cleaned= re.sub('<.*?>', '', withOutComments, flags=re.S)\n",
    "    testoPulito = removeNestedParentheses(cleaned)\n",
    "    wikicode = mwparserfromhell.parse(testoPulito)\n",
    "    templates = wikicode.filter_templates()\n",
    "    text = \" \".join([testo for testo in testoPulito.split() if testo not in templates])\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    return text.lower"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pulisco per bene il file tenendo soltanto le parole, pulendole da tutti i tag (parentesi quadrate, ad esempio) e da tutti i simboli di punteggiatura.\n",
    "Inoltre vado anche a cancellare i paragrafi ed i loro titoli. Da qui si creerá un metodo che verrá utilizzato "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pulizia(text):\n",
    "    \n",
    "    finalText = ''\n",
    "    clearedText = ''\n",
    "    for x in text.splitlines():\n",
    "        withoutGraphParenthesis = re.sub(r'\\{\\{[^\\}]*\\}\\}', '', text)\n",
    "        withOutFile = re.sub(r'\\[\\[file:[^\\]]*\\]\\]', '', withoutGraphParenthesis)\n",
    "        withoutPipe= re.sub(r\"\\[\\[[^|\\]]*\\|([^|\\]]*)]]\", r\"\\1\", withOutFile)\n",
    "        withoutParenthesis = re.sub(r'\\[\\[.*?\\]\\]', '', withoutPipe)\n",
    "        withOutRef = re.sub(r'<\\/?ref[^>]*>', '', withoutParenthesis)\n",
    "        withOutComments= re.sub('<!--.*?-->', '', withOutRef)\n",
    "        withOutClosedRef = re.sub(r'</ref>', '', withOutComments)\n",
    "        clearedText = clearedText+\"\".join(withOutClosedRef)\n",
    "        \n",
    "    content = []\n",
    "    skip = False\n",
    "    for l in clearedText.splitlines():\n",
    "        line = l.strip()\n",
    "        if \"=references=\" in line.lower():\n",
    "            skip = True  # replace with break if this is the last section\n",
    "            break\n",
    "        if \"= further reading =\" in line.lower():\n",
    "            skip = True  # replace with break if this is the last section\n",
    "            continue\n",
    "        \"\"\" if section_title_re.match(line):\n",
    "            skip = False\n",
    "            continue \"\"\"\n",
    "        if skip:\n",
    "            continue\n",
    "        content.append(line)\n",
    "\n",
    "    for x in content:\n",
    "        if x != \"\":\n",
    "            cleared = re.sub(r'==+.*?==+', '', x)\n",
    "            punctuation_free = re.sub(r'[^\\w\\s]', '', cleared)\n",
    "            finalText = finalText + punctuation_free.lower().strip() + \" \"\n",
    "    finalText = ' '.join(finalText.split())\n",
    "    finalText = re.sub(r'[^\\w\\s]', '', finalText)\n",
    "    return finalText.lower"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vado a creare un file csv con i titoli della pagina e le parole in essa contenute. Vado inoltre ad eliminare tutte le stop words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30,700,000 rows written of 356,900,000, percents: 8.60%\r"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 46\u001b[0m\n\u001b[1;32m     44\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([word \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m text\u001b[39m.\u001b[39msplit() \u001b[39mif\u001b[39;00m word \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m stop_words])\n\u001b[1;32m     45\u001b[0m \u001b[39m#print(\"Count text: \" + str(j) + \" \"+pulizia(text))\u001b[39;00m\n\u001b[0;32m---> 46\u001b[0m text \u001b[39m=\u001b[39m cleanUp(text)\n\u001b[1;32m     47\u001b[0m \u001b[39m#words_list.append(text)\u001b[39;00m\n\u001b[1;32m     48\u001b[0m wordsWriter\u001b[39m.\u001b[39mwriterow([j, text])\n",
      "Cell \u001b[0;32mIn[43], line 46\u001b[0m, in \u001b[0;36mcleanUp\u001b[0;34m(text)\u001b[0m\n\u001b[1;32m     44\u001b[0m cleaned\u001b[39m=\u001b[39m re\u001b[39m.\u001b[39msub(\u001b[39m'\u001b[39m\u001b[39m<.*?>\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m'\u001b[39m, withOutComments, flags\u001b[39m=\u001b[39mre\u001b[39m.\u001b[39mS)\n\u001b[1;32m     45\u001b[0m testoPulito \u001b[39m=\u001b[39m removeNestedParentheses(cleaned)\n\u001b[0;32m---> 46\u001b[0m wikicode \u001b[39m=\u001b[39m mwparserfromhell\u001b[39m.\u001b[39;49mparse(testoPulito)\n\u001b[1;32m     47\u001b[0m templates \u001b[39m=\u001b[39m wikicode\u001b[39m.\u001b[39mfilter_templates()\n\u001b[1;32m     48\u001b[0m text \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m \u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mjoin([testo \u001b[39mfor\u001b[39;00m testo \u001b[39min\u001b[39;00m testoPulito\u001b[39m.\u001b[39msplit() \u001b[39mif\u001b[39;00m testo \u001b[39mnot\u001b[39;00m \u001b[39min\u001b[39;00m templates])\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mwparserfromhell/utils.py:53\u001b[0m, in \u001b[0;36mparse_anything\u001b[0;34m(value, context, skip_style_tags)\u001b[0m\n\u001b[1;32m     51\u001b[0m     \u001b[39mreturn\u001b[39;00m Wikicode(SmartList([value]))\n\u001b[1;32m     52\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mstr\u001b[39m):\n\u001b[0;32m---> 53\u001b[0m     \u001b[39mreturn\u001b[39;00m Parser()\u001b[39m.\u001b[39;49mparse(value, context, skip_style_tags)\n\u001b[1;32m     54\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(value, \u001b[39mbytes\u001b[39m):\n\u001b[1;32m     55\u001b[0m     \u001b[39mreturn\u001b[39;00m Parser()\u001b[39m.\u001b[39mparse(value\u001b[39m.\u001b[39mdecode(\u001b[39m\"\u001b[39m\u001b[39mutf8\u001b[39m\u001b[39m\"\u001b[39m), context, skip_style_tags)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mwparserfromhell/parser/__init__.py:85\u001b[0m, in \u001b[0;36mParser.parse\u001b[0;34m(self, text, context, skip_style_tags)\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Parse *text*, returning a :class:`.Wikicode` object tree.\u001b[39;00m\n\u001b[1;32m     70\u001b[0m \n\u001b[1;32m     71\u001b[0m \u001b[39mIf given, *context* will be passed as a starting context to the parser.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[39mbe raised.\u001b[39;00m\n\u001b[1;32m     83\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m     84\u001b[0m tokens \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokenizer\u001b[39m.\u001b[39mtokenize(text, context, skip_style_tags)\n\u001b[0;32m---> 85\u001b[0m code \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_builder\u001b[39m.\u001b[39;49mbuild(tokens)\n\u001b[1;32m     86\u001b[0m \u001b[39mreturn\u001b[39;00m code\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mwparserfromhell/parser/builder.py:332\u001b[0m, in \u001b[0;36mBuilder.build\u001b[0;34m(self, tokenlist)\u001b[0m\n\u001b[1;32m    330\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_push()\n\u001b[1;32m    331\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_tokens:\n\u001b[0;32m--> 332\u001b[0m     node \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_handle_token(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_tokens\u001b[39m.\u001b[39;49mpop())\n\u001b[1;32m    333\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_write(node)\n\u001b[1;32m    334\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pop()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mwparserfromhell/parser/builder.py:321\u001b[0m, in \u001b[0;36mBuilder._handle_token\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Handle a single token.\"\"\"\u001b[39;00m\n\u001b[1;32m    320\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 321\u001b[0m     \u001b[39mreturn\u001b[39;00m _HANDLERS[\u001b[39mtype\u001b[39;49m(token)](\u001b[39mself\u001b[39;49m, token)\n\u001b[1;32m    322\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mKeyError\u001b[39;00m:\n\u001b[1;32m    323\u001b[0m     err \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39m_handle_token() got unexpected \u001b[39m\u001b[39m{0}\u001b[39;00m\u001b[39m\"\u001b[39m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mwparserfromhell/parser/builder.py:275\u001b[0m, in \u001b[0;36mBuilder._handle_tag\u001b[0;34m(self, token)\u001b[0m\n\u001b[1;32m    273\u001b[0m close_tokens \u001b[39m=\u001b[39m (tokens\u001b[39m.\u001b[39mTagCloseSelfclose, tokens\u001b[39m.\u001b[39mTagCloseClose)\n\u001b[1;32m    274\u001b[0m implicit, attrs, contents, closing_tag \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m, [], \u001b[39mNone\u001b[39;00m, \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 275\u001b[0m wiki_markup, invalid \u001b[39m=\u001b[39m token\u001b[39m.\u001b[39mwiki_markup, token\u001b[39m.\u001b[39;49minvalid \u001b[39mor\u001b[39;00m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m    276\u001b[0m wiki_style_separator, closing_wiki_markup \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m, wiki_markup\n\u001b[1;32m    277\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_push()\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/mwparserfromhell/parser/tokens.py:51\u001b[0m, in \u001b[0;36mToken.__getattr__\u001b[0;34m(self, key)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getattr__\u001b[39m(\u001b[39mself\u001b[39m, key):\n\u001b[0;32m---> 51\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget(key)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "f= open(\"file.csv\", \"w+\")\n",
    "writer = csv.writer(f)\n",
    "\n",
    "fileWords = open(\"fileWords.csv\", \"w+\")\n",
    "fileTitles = open(\"fileTitles.csv\", \"w+\")\n",
    "\n",
    "wordsWriter = csv.writer(fileWords)\n",
    "titlesWriter = csv.writer(fileTitles)\n",
    "\n",
    "writer.writerow(header)\n",
    "section_title_re = re.compile(\"^=+\\s+.*\\s+=+$\")\n",
    "skip = False\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "totalCount = 0\n",
    "titles_list = []\n",
    "words_list = []\n",
    "file_xml= ''\n",
    "if os.path.isfile(\"/home/fabbro/Documents/Cartella/fileWiki.xml\"):\n",
    "    file_xml = \"/home/fabbro/Documents/Cartella/fileWiki.xml\"\n",
    "elif os.path.isfile(\"/home/fabbro/Documents/Big-Data/file.xml\"):\n",
    "    file_xml = \"/home/fabbro/Documents/Big-Data/file.xml\"\n",
    "else:\n",
    "    print(\"File non trovato\")\n",
    "tupla_titolo = ()\n",
    "tupla_testo = ()\n",
    "for event, elem in etree.iterparse(file_xml):\n",
    "    text = \"\"\n",
    "    title=\"\"\n",
    "    \n",
    "    if('title' in str(elem.tag)):\n",
    "        if(elem.text is not None):\n",
    "            i = i+1\n",
    "            title = elem.text.lower()\n",
    "            #titles_list.append(title)\n",
    "            #print(\"Count title: \"+str(i)+\" \"+title.lower())\n",
    "            titlesWriter.writerow([i, title])\n",
    "\n",
    "    if('text' in str(elem.tag)):\n",
    "        if(elem.text is not None):\n",
    "            j = j+1\n",
    "            text = elem.text.lower()\n",
    "            text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "            #print(\"Count text: \" + str(j) + \" \"+pulizia(text))\n",
    "            text = cleanUp(text)\n",
    "            #words_list.append(text)\n",
    "            wordsWriter.writerow([j, text])\n",
    "    elem.clear()\n",
    "    totalCount += 1\n",
    "    if totalCount > 1 and (totalCount % 100000) == 0:\n",
    "            percents = (totalCount/356900000)*100\n",
    "            print(\"{:,}\".format(totalCount)+f\" rows written of 356,900,000, percents: {percents:.2f}%\", end=\"\\r\")\n",
    "#print(\"Are rows and titles equals? \"+str(len(words_list) == len(titles_list)))\n",
    "#print(\"Words ha la lunghezza di: \"+str(len(words_list))+\"mentre il contatore: \"+str(j))\n",
    "#print(\"Titles ha la lunghezza di: \"+str(len(titles_list))+\"mentre il contatore: \"+str(i))\n",
    "\n",
    "\"\"\" if len(lista) == 2:\n",
    "        writer.writerow([lista[0], lista[1]])\n",
    "        lista=[] \"\"\"\n",
    "        \n",
    "''' listaTitoli = []\n",
    "    listaTitoli.append(title)\n",
    "    print(listaTitoli[0])\n",
    "    if i == j and text != \"\":\n",
    "        print(\"Counter: \"+str(i)+\" - title: \"+listaTitoli[0]+\" text: \"+pulizia(text))'''\n",
    "f.close()\n",
    "print(\"-------------------------------------------DONE------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f= open(\"file.csv\", \"w+\")\n",
    "writer = csv.writer(f)\n",
    "\n",
    "fileWords = open(\"fileWords.csv\", \"w+\")\n",
    "fileTitles = open(\"fileTitles.csv\", \"w+\")\n",
    "\n",
    "wordsWriter = csv.writer(fileWords)\n",
    "titlesWriter = csv.writer(fileTitles)\n",
    "\n",
    "writer.writerow(header)\n",
    "section_title_re = re.compile(\"^=+\\s+.*\\s+=+$\")\n",
    "skip = False\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "totalCount = 0\n",
    "titles_list = []\n",
    "words_list = []\n",
    "file_xml= ''\n",
    "if os.path.isfile(\"/home/fabbro/Documents/Cartella/fileWiki.xml\"):\n",
    "    file_xml = \"/home/fabbro/Documents/Cartella/fileWiki.xml\"\n",
    "elif os.path.isfile(\"/home/fabbro/Documents/Big-Data/file.xml\"):\n",
    "    file_xml = \"/home/fabbro/Documents/Big-Data/file.xml\"\n",
    "else:\n",
    "    print(\"File non trovato\")\n",
    "tupla_titolo = ()\n",
    "tupla_testo = ()\n",
    "for event, elem in etree.iterparse(file_xml):\n",
    "    text = \"\"\n",
    "    title=\"\"\n",
    "    \n",
    "    if('title' in str(elem.tag)):\n",
    "        if(elem.text is not None):\n",
    "            i = i+1\n",
    "            title = elem.text.lower()\n",
    "            titlesWriter.writerow([i, title])\n",
    "\n",
    "    if('text' in str(elem.tag)):\n",
    "        if(elem.text is not None):\n",
    "            j = j+1\n",
    "            text = elem.text.lower()\n",
    "            text = \" \".join([word for word in text.split() if word not in stop_words])\n",
    "            text = cleanUp(text)\n",
    "            wordsWriter.writerow([j, text])\n",
    "    elem.clear()\n",
    "    totalCount += 1\n",
    "    if totalCount > 1 and (totalCount % 100000) == 0:\n",
    "            percents = (totalCount/356900000)*100\n",
    "            print(\"{:,}\".format(totalCount)+f\" rows written of 356,900,000, percents: {percents:.2f}%\", end=\"\\r\")\n",
    "f.close()\n",
    "print(\"-------------------------------------------DONE------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title,Text\n",
      "-------------------------------\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 18\u001b[0m\n\u001b[1;32m     16\u001b[0m inputFile \u001b[39m=\u001b[39minputFile\u001b[39m.\u001b[39mread()\u001b[39m.\u001b[39msplitlines()\n\u001b[1;32m     17\u001b[0m \u001b[39mfor\u001b[39;00m x \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m5\u001b[39m):\n\u001b[0;32m---> 18\u001b[0m     \u001b[39mprint\u001b[39m(inputFile[x])\n\u001b[1;32m     19\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m-------------------------------\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "\"\"\" \n",
    "input_filename = '/home/fabbro/Documents/Big-Data/file.csv'\n",
    "#input_filename = \"/Users/dcarra/Desktop/OneDrive - Università degli Studi di Verona/courses/BigData/PhD_course/2021/lab_notebooks/datasets/short_stories_I.txt\"\n",
    "input_file = sc.textFile(input_filename)\n",
    "\n",
    "#num_lines = input_file.count()\n",
    "#print(\"The number of lines in the input file is:\", num_lines)\n",
    "\n",
    "print(input_file.take(1))\n",
    "wordsList = input_file.filter(bool) \\\n",
    "            .flatMap(lambda line: line.split(\" \"))\\\n",
    "            .map(lambda w: w.lower())\n",
    "wordsKeyValue = wordsList.flatMap(lambda w: (w,1))\n",
    "print(wordsKeyValue.take(5)) \"\"\"\n",
    "inputFile = open(\"/home/fabbro/Documents/Big-Data/file.csv\", \"r\")\n",
    "inputFile =inputFile.read().splitlines()\n",
    "for x in range(5):\n",
    "    print(inputFile[x])\n",
    "    print(\"-------------------------------\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'linecache' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m num_Words \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(linecache\u001b[39m.\u001b[39mgetlines(\u001b[39m\"\u001b[39m\u001b[39mfileWords.csv\u001b[39m\u001b[39m\"\u001b[39m)) \n\u001b[1;32m      2\u001b[0m \u001b[39mprint\u001b[39m(num_Words)\n\u001b[1;32m      3\u001b[0m numTitles \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(linecache\u001b[39m.\u001b[39mgetlines(\u001b[39m\"\u001b[39m\u001b[39mfileTitles.csv\u001b[39m\u001b[39m\"\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'linecache' is not defined"
     ]
    }
   ],
   "source": [
    "num_Words = len(linecache.getlines(\"fileWords.csv\")) \n",
    "print(num_Words)\n",
    "numTitles = len(linecache.getlines(\"fileTitles.csv\"))\n",
    "print(numTitles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[39m# Utilizza un ciclo per leggere il file CSV in blocchi\u001b[39;00m\n\u001b[1;32m      9\u001b[0m num_rows \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[0;32m---> 10\u001b[0m \u001b[39mfor\u001b[39;00m chunk \u001b[39min\u001b[39;00m pd\u001b[39m.\u001b[39mread_csv(file_path, chunksize\u001b[39m=\u001b[39mchunk_size):\n\u001b[1;32m     11\u001b[0m     num_rows \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(chunk)\n\u001b[1;32m     12\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mstr\u001b[39m(chunk\u001b[39m.\u001b[39miloc[:,\u001b[39m1\u001b[39m])\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m\\r\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "# Specifica il nome del file CSV e la dimensione del blocco\n",
    "from time import sleep\n",
    "\n",
    "\n",
    "file_path = \"fileWords.csv\"\n",
    "chunk_size = 10\n",
    "\n",
    "# Utilizza un ciclo per leggere il file CSV in blocchi\n",
    "num_rows = 0\n",
    "for chunk in pd.read_csv(file_path, chunksize=chunk_size):\n",
    "    num_rows += len(chunk)\n",
    "    print(str(chunk.iloc[:,1])+'\\r')\n",
    "    sleep(5)\n",
    "print(\"Il file CSV contiene {:,}\".format(num_rows), \"righe.\", end=\"\\r\")\n",
    "# Stampa il numero di righe nel file CSV\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                             anarchism\n",
      "1                    afghanistanhistory\n",
      "2                  afghanistangeography\n",
      "3                     afghanistanpeople\n",
      "4             afghanistancommunications\n",
      "                      ...              \n",
      "99995             rockleigh, new jersey\n",
      "99996            rutherford, new jersey\n",
      "99997             teterboro, new jersey\n",
      "99998    upper saddle river, new jersey\n",
      "99999            wood-ridge, new jersey\n",
      "Name: accessiblecomputing, Length: 100000, dtype: object\n",
      "\n",
      "Il file CSV contiene 100,000 righe.\r"
     ]
    }
   ],
   "source": [
    "# Specifica il nome del file CSV e la dimensione del blocco\n",
    "file_path = \"fileTitles.csv\"\n",
    "chunk = 100000\n",
    "\n",
    "# Utilizza un ciclo per leggere il file CSV in blocchi\n",
    "num_righe = 0\n",
    "for chunks in pd.read_csv(file_path, chunksize=chunk):\n",
    "    num_righe += len(chunks)\n",
    "    print(str(chunks.iloc[:,1])+'\\n')\n",
    "    if num_righe > 100:\n",
    "        break\n",
    "print(\"Il file CSV contiene {:,}\".format(num_righe), \"righe.\", end=\"\\r\")\n",
    "# Stampa il numero di righe nel file CSV"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inizio ad utilizzare PySpark utilizzando SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/29 16:37:58 WARN Utils: Your hostname, kerah resolves to a loopback address: 127.0.1.1; using 192.168.178.79 instead (on interface wlp38s0)\n",
      "23/03/29 16:37:58 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/29 16:37:59 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder.appName(\"mySparkApp\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Carico i due file come DF </b> <i> poi unendoli in un unico DF tenendo come chiave d'unione l'index</i>. Vado quindi a pulire quel che é stato generato (una cartella) mantenendo solo quel che ci serve a noi: il file csv con i dati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles_df = spark.read.csv(\"fileUno.csv\", header=True, inferSchema=True)\n",
    "text_df = spark.read.csv(\"fileDue.csv\", header=True, inferSchema=True)\n",
    "\n",
    "merged_df = titles_df.join(text_df, \"index\")\n",
    "\n",
    "merged_df.write.csv(\"merged_file\", header=True)\n",
    "\n",
    "for filename in os.listdir(\"merged_file\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.rename(os.path.join(\"merged_file\", filename), os.path.join(\"\", \"merged.csv\"))\n",
    "        shutil.rmtree(\"merged_file\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora bisogna mappare le parole (contando quante ce ne sono) presenti in ogni cella del file CSV. Stampo inoltre anche il titolo per far capire dove siamo arrivati."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"merged.csv\")\n",
    "with open(\"countedWords.csv\", \"w+\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Title\", \"Word\", \"Counter\"])\n",
    "    for x in range(df.count()):\n",
    "        title = df.collect()[x][\"Title\"]\n",
    "        word = []\n",
    "        counter = []\n",
    "        #print(\"----------- \"+df.collect()[x][\"Title\"]+\" -----------\")\n",
    "        cella = df.collect()[x][\"Text\"]\n",
    "        words_df = spark.createDataFrame([(cella,)], ['text'])\n",
    "        words = words_df.select(explode(split(lower('text'), ' ')).alias('word')) \\\n",
    "                        .groupBy('word').agg(count('*').alias('count')) \\\n",
    "                        .orderBy('count', ascending=False)\n",
    "        word_counts = words.rdd.map(lambda row: (row['word'], row['count'])).collectAsMap()\n",
    "        for x in word_counts:\n",
    "            #print(\"Parola: {}, valore: {}\".format(x, word_counts[x]))\n",
    "            word.append(x)\n",
    "            counter.append(word_counts[x])\n",
    "        writer.writerow([title, word, counter])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>L’output deve contenere, per ogni parola, la lista di pagine di wikipedia\n",
    "che contengono quella parola</b>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"merged.csv\")\n",
    "\n",
    "with open(\"reversedIndexing.csv\", \"w+\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Word\", \"Titles\"])\n",
    "    for x in range(df.count()):\n",
    "        title = df.collect()[x][\"Title\"]\n",
    "        word = []\n",
    "        counter = []\n",
    "        #print(\"----------- \"+df.collect()[x][\"Title\"]+\" -----------\")\n",
    "        cella = df.collect()[x][\"Text\"]\n",
    "        words_df = spark.createDataFrame([(cella,)], ['text'])\n",
    "        words = words_df.select(explode(split(lower('text'), ' ')).alias('word')) \\\n",
    "                        .groupBy('word').agg(count('*').alias('count')) \\\n",
    "                        .orderBy('count', ascending=True)\n",
    "        word_counts = words.rdd.map(lambda row: (row['word'], row['count'])).collectAsMap()\n",
    "        for x in word_counts:\n",
    "            #print(\"Parola: {}, valore: {}\".format(x, word_counts[x]))\n",
    "            word.append(x)\n",
    "            counter.append(word_counts[x])\n",
    "        writer.writerow([title, word, counter])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leggiamo tutte le parole presenti nella colonna \"Text\" del file CSV. Utilizziamo un set in quanto non vogliamo che ci siano parole ripetute. Poi lo trasformiamo in una lista per renderlo indicizzabile."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"merged.csv\")\n",
    "word_list = []\n",
    "tempSet = set()\n",
    "for x in range(df.count()):\n",
    "    tempList = []\n",
    "    if len(df.collect()[x][\"Text\"].split()) > 1:\n",
    "        tempList= df.collect()[x][\"Text\"].lower().split()\n",
    "        for x in tempList:\n",
    "            tempSet.add(x)\n",
    "    else:\n",
    "        tempSet.add(df.collect()[x][\"Text\"].lower())\n",
    "word_list = list(tempSet)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora controllo quali parole sono presenti nel file finale da controllare. Se le parole sono presenti, aggiungo il titolo ad una lista. Si creerá infine una riga in un file CSV con la parola e la lista di titoli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/03/29 16:38:17 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n"
     ]
    }
   ],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"merged.csv\")\n",
    "with open(\"reversedIndexing.csv\", \"w+\") as f:\n",
    "    writer = csv.writer(f)\n",
    "    writer.writerow([\"Word\", \"Titles\"])\n",
    "    #controllo parola per parola\n",
    "    for x in word_list:\n",
    "        title_list = []\n",
    "        #controllo ogni singola riga del file CSV\n",
    "        for y in range(df.count()):\n",
    "            if x in df.collect()[y][\"Text\"].lower().split():\n",
    "                #print(\"La parola '{}' è presente nel titolo '{}'\".format(x, df.collect()[y][\"Title\"]))\n",
    "                title_list.append(df.collect()[y][\"Title\"])\n",
    "        writer.writerow([x, title_list])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
