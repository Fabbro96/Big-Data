{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Requirements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install mwparserfromhell\n",
    "%pip install lxml\n",
    "%pip install pyspark\n",
    "%pip install nltk\n",
    "%pip install numba\n",
    "%pip install pandas\n",
    "%pip install matplotlib\n",
    "%pip install scipy\n",
    "%pip install scikit-learn\n",
    "%pip install seaborn"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Various imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import re\n",
    "import os.path\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import glob\n",
    "import mwparserfromhell\n",
    "import nltk\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mtick\n",
    "import numpy as np\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from lxml import etree\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import lower, explode, split, regexp_replace, sum\n",
    "from scipy.stats import norm\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.datasets import make_blobs"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download delle stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "nltk.download(\"stopwords\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esempio sul funzionamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "def removeNestedParentheses(s):\n",
    "    lines = s.split('\\n')\n",
    "    print(len(lines))\n",
    "    ret = []\n",
    "    for line in lines:\n",
    "        curr_line = ''\n",
    "        skip = 0\n",
    "        for i in line:\n",
    "            if i == '[':\n",
    "                skip += 1\n",
    "            elif i == ']'and skip > 0:\n",
    "                skip -= 1\n",
    "            elif skip == 0:\n",
    "                curr_line += i\n",
    "        ret.append(curr_line+\"\\n\")\n",
    "    return '\\n'.join(ret)\n",
    "\n",
    "text = '''\n",
    "I has a template! {{foo|bar|baz|eggs=spam}} See it <nowiki>or no<!-- revealed --></nowiki>[[File:wiki.png|thumb|Wikipedia logo]]? [[fox]] and [[dog|puppy]] New York also has [[public transport|public transportation]].\n",
    "\n",
    "\n",
    "New York is a state in the Northeastern United States and is the 27th-most extensive, fourth-most populous, and seventh-most densely populated U.S. state. New York is bordered by New Jersey and Pennsylvania to the south and Connecticut, Massachusetts, and Vermont to the east. The state has a maritime border in the Atlantic Ocean with Rhode Island, east of Long Island, as well as an international border with the Canadian provinces of Quebec to the north and Ontario to the west and north. The state of New York, with an estimated 19.8 million residents in 2015, is often referred to as New York State to distinguish it from New York City, the state's most populous city and its economic hub.\n",
    "With an estimated population of 8.55 million in 2015, New York City is the most populous city in the United States and the premier gateway for legal immigration to the United States. The New York City Metropolitan Area is one of the most populous urban agglomerations in the world. New York City is a global city, exerting a significant impact upon commerce, finance, media, art, fashion, research, technology, education, and entertainment, its fast pace defining the term New York minute. The home of the United Nations Headquarters, New York City is an important center for international diplomacy and has been described as the cultural and financial capital of the world, as well as the world's most economically powerful city. New York City makes up over 40% of the population of New York State. Two-thirds of the state's population lives in the New York City Metropolitan Area, and nearly 40% live on Long Island. Both the state and New York City were named for the 17th century Duke of York, future King James II of England. The next four most populous cities in the state are Buffalo, Rochester, Yonkers, and Syracuse, while the state capital is Albany.\n",
    "The earliest Europeans in New York were French colonists and Jesuit missionaries who arrived southward from settlements at Montreal for trade and proselytizing. New York had been inhabited by tribes of Algonquian and Iroquoian-speaking Native Americans for several hundred years by the time Dutch settlers moved into the region in the early 17th century. In 1609, the region was first claimed by Henry Hudson for the Dutch, who built Fort Nassau in 1614 at the confluence of the Hudson and Mohawk rivers, where the present-day capital of Albany later developed. The Dutch soon also settled New Amsterdam and parts of the Hudson Valley, establishing the colony of New Netherland, a multicultural community from its earliest days and a center of trade and immigration. The British annexed the colony from the Dutch in 1664. The borders of the British colony, the Province of New York, were similar to those of the present-day state.\n",
    "Many landmarks in New York are well known to both international and domestic visitors, with New York State hosting four of the world's ten most-visited tourist attractions in 2013: Times Square, Central Park, Niagara Falls (shared with Ontario), and Grand Central Terminal. New York is home to the Statue of Liberty, a symbol of the United States and its ideals of freedom, democracy, and opportunity. In the 21st century, New York has emerged as a global node of creativity and entrepreneurship, social tolerance, and environmental sustainability. New York's higher education network comprises approximately 200 colleges and universities, including Columbia University, Cornell University, New York University, and Rockefeller University, which have been ranked among the top 35 in the world.\n",
    "\n",
    "\n",
    "== History ==\n",
    "\n",
    "\n",
    "=== 16th century ===\n",
    "In 1524, Giovanni da Verrazzano, an Italian explorer in the service of the French crown, explored the Atlantic coast of North America between the Carolinas and Newfoundland, including New York Harbor and Narragansett Bay. On April 17, 1524 Verrazanno entered New York Bay, by way of the Strait now called the Narrows into the northern bay which he named Santa Margherita, in honour of the King of France's sister. Verrazzano described it as \"a vast coastline with a deep delta in which every kind of ship could pass\" and he adds: \"that it extends inland for a league and opens up to form a beautiful lake. This vast sheet of water swarmed with native boats\". He landed on the tip of Manhattan and perhaps on the furthest point of Long Island. Verrazanno's stay in this place was interrupted by a storm which pushed him north towards Martha's Vineyard.\n",
    "In 1540 French traders from New France built a chateau on Castle Island, within present-day Albany; due to flooding, it was abandoned the next year. In 1614, the Dutch under the command of Hendrick Corstiaensen, rebuilt the French chateau, which they called Fort Nassau. Fort Nassau was the first Dutch settlement in North America, and was located along the Hudson River, also within present-day Albany. The small fort served as a trading post and warehouse. Located on the Hudson River flood plain, the rudimentary \"fort\" was washed away by flooding in 1617, and abandoned for good after Fort Orange (New Netherland) was built nearby in 1623.\n",
    "\n",
    "\n",
    "=== 17th century ===\n",
    "\n",
    "Henry Hudson's 1609 voyage marked the beginning of European involvement with the area. Sailing for the Dutch East India Company and looking for a passage to Asia, he entered the Upper New York Bay on September 11 of that year. Word of his findings encouraged Dutch merchants to explore the coast in search for profitable fur trading with local Native American tribes.\n",
    "During the 17th century, Dutch trading posts established for the trade of pelts from the Lenape, Iroquois, and other tribes were founded in the colony of New Netherland. The first of these trading posts were Fort Nassau (1614, near present-day Albany); Fort Orange (1624, on the Hudson River just south of the current city of Albany and created to replace Fort Nassau), developing into settlement Beverwijck (1647), and into what became Albany; Fort Amsterdam (1625, to develop into the town New Amsterdam which is present-day New York City); and Esopus, (1653, now Kingston). The success of the patroonship of Rensselaerswyck (1630), which surrounded Albany and lasted until the mid-19th century, was also a key factor in the early success of the colony. The English captured the colony during the Second Anglo-Dutch War and governed it as the Province of New York. The city of New York was recaptured by the Dutch in 1673 during the Third Anglo-Dutch War (1672–1674) and renamed New Orange. It was returned to the English under the terms of the Treaty of Westminster a year later.\n",
    "\n",
    "\n",
    "== References ==\n",
    "\n",
    "\n",
    "== Further reading ==\n",
    "\n",
    "French, John Homer (1860). Historical and statistical gazetteer of New York State. Syracuse, New York: R. Pearsall Smith. OCLC 224691273. (Full text via Google Books.)\n",
    "New York State Historical Association (1940). New York: A Guide to the Empire State. New York City: Oxford University Press. ISBN 978-1-60354-031-5. OCLC 504264143. (Full text via Google Books.)\n",
    "\n",
    "\n",
    "== External links ==\n",
    "New York at DMOZ\n",
    " Geographic data related to New York at OpenStreetMap'''\n",
    "\n",
    "\n",
    "\n",
    "section_title_re = re.compile(\"^=+\\s+.*\\s+=+$\")\n",
    "content = ''\n",
    "skip = False\n",
    "\n",
    "for l in text.splitlines():\n",
    "    line = l.strip()\n",
    "    if \"= references =\" in line.lower():\n",
    "        skip = True  # replace with break if this is the last section\n",
    "        break\n",
    "    if \"= further reading =\" in line.lower():\n",
    "        skip = True  # replace with break if this is the last section\n",
    "        continue\n",
    "    if section_title_re.match(line):\n",
    "        skip = False\n",
    "        continue\n",
    "    if skip:\n",
    "        continue\n",
    "    content+=line+'\\n'\n",
    "    \n",
    "\"\"\" for x in content:\n",
    "    if x != \"\":\n",
    "        print(x.lower()+\"\\n\")\n",
    " \"\"\"\n",
    " \n",
    "withoutPipeLinks = (re.sub(r\"\\[\\[[^|\\]]*\\|([^|\\]]*)]]\", r\"\\1\", content, flags=re.S))\n",
    "withOutComments= re.sub('<!--.*?-->', '', withoutPipeLinks, flags=re.S)\n",
    "cleaned= re.sub('<.*?>', '', withOutComments, flags=re.S)\n",
    "testoPulito = removeNestedParentheses(cleaned)\n",
    "wikicode = mwparserfromhell.parse(testoPulito)\n",
    "templates = wikicode.filter_templates()\n",
    "text = \" \".join([testo for testo in testoPulito.split() if testo not in templates])\n",
    "print(text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "----"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Processamento del testo</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo creato per pulire il file, mantenendo soltanto le parole, eliminando tutti i tag (parentesi quadrate, ad esempio) e tutti i simboli di punteggiatura.\n",
    "Inoltre vado anche a cancellare i paragrafi ed i loro titoli. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeNestedParentheses(s):\n",
    "    lines = s.split('\\n')\n",
    "    ret = []\n",
    "    for line in lines:\n",
    "        curr_line = ''\n",
    "        skip = 0\n",
    "        for i in line:\n",
    "            if i == '[' or i == '{' :\n",
    "                skip += 1\n",
    "            elif (i == ']' or i == '}' ) and skip > 0:\n",
    "                skip -= 1\n",
    "            elif skip == 0:\n",
    "                curr_line += i\n",
    "        ret.append(curr_line+\"\\n\")\n",
    "    return '\\n'.join(ret)\n",
    "\n",
    "def cleanUp(text):\n",
    "    section_title_re = re.compile(\"^=+\\s+.*\\s+=+$\")\n",
    "    content = ''\n",
    "    skip = False\n",
    "\n",
    "    for l in text.splitlines():\n",
    "        line = l.strip()\n",
    "        if \"= references =\" in line.lower():\n",
    "            skip = True\n",
    "            break\n",
    "        if \"= further reading =\" in line.lower():\n",
    "            skip = True \n",
    "            continue\n",
    "        if section_title_re.match(line):\n",
    "            skip = False\n",
    "            continue\n",
    "        if skip:\n",
    "            continue\n",
    "        content+=line+'\\n'\n",
    "    \n",
    "    withoutPipeLinks = (re.sub(r\"\\[\\[[^|\\]]*\\|([^|\\]]*)]]\", r\"\\1\", content, flags=re.S))\n",
    "    withOutComments= re.sub('<!--.*?-->', '', withoutPipeLinks, flags=re.S)\n",
    "    cleaned= re.sub('<.*?>', '', withOutComments, flags=re.S)\n",
    "    testoPulito = removeNestedParentheses(cleaned)\n",
    "    wikicode = mwparserfromhell.parse(testoPulito)\n",
    "    templates = wikicode.filter_templates()\n",
    "    text = \" \".join([testo for testo in testoPulito.split() if testo not in templates])\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    if text == \"\":\n",
    "        return \"NullTextFound\"\n",
    "    else:\n",
    "        return text"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metodo destinato ad eliminare tutte le <i>stop words</i>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"english\"))\n",
    "def remove_w(text):\n",
    "    return ' '.join(w for w in text.split() if w not in stop_words)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione di un file csv contenente i titoli della pagina e le parole contenute all'interno del file XML.\n",
    "\\\n",
    "Tengo conto dei primi 1000000 elementi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileWords = open(\"fileWords.csv\", \"w+\")\n",
    "fileTitles = open(\"fileTitles.csv\", \"w+\")\n",
    "\n",
    "wordsWriter = csv.writer(fileWords)\n",
    "titlesWriter = csv.writer(fileTitles)\n",
    "\n",
    "titlesWriter.writerow([\"index\", \"title\"])\n",
    "wordsWriter.writerow([\"index\", \"text\"])\n",
    "section_title_re = re.compile(\"^=+\\s+.*\\s+=+$\")\n",
    "skip = False\n",
    "\n",
    "i = 0\n",
    "j = 0\n",
    "totalCount = 0\n",
    "titles_list = []\n",
    "words_list = []\n",
    "file_xml= ''\n",
    "if os.path.isfile(\"fileWiki.xml\"):\n",
    "    file_xml = \"fileWiki.xml\"\n",
    "elif os.path.isfile(\"file.xml\"):\n",
    "    file_xml = \"file.xml\"\n",
    "else:\n",
    "    print(\"File non trovato\")\n",
    "tupla_titolo = ()\n",
    "tupla_testo = ()\n",
    "for event, elem in etree.iterparse(file_xml):\n",
    "    text = \"\"\n",
    "    title=\"\"\n",
    "    \n",
    "    if('title' in str(elem.tag)):\n",
    "        if(elem.text is not None):\n",
    "            i = i+1\n",
    "            title = elem.text.lower()\n",
    "            titlesWriter.writerow([i, title])\n",
    "\n",
    "    if('text' in str(elem.tag)):\n",
    "        if(elem.text is not None):\n",
    "            j = j+1\n",
    "            text = remove_w(cleanUp(elem.text.lower()))\n",
    "            wordsWriter.writerow([j, text])\n",
    "\n",
    "    if j == 1000000 and i == 1000000:\n",
    "        break\n",
    "    elem.clear()\n",
    "    totalCount += 1\n",
    "    if totalCount > 1 and (totalCount % 1000) == 0:\n",
    "            percents = (totalCount/1000000)*100\n",
    "            print(f\"Percents: {percents:.2f}%\", end=\"\\r\")\n",
    "            if percents == 100:\n",
    "                break\n",
    "\n",
    "print(\"-------------------------------------------DONE------------------------------------------------------\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1> Analisi dei dati </h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inizializziamo spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"mySparkApp\").config(\"spark.driver.memory\", \"4g\").config(\"spark.driver.maxResultSize\", \"12g\").getOrCreate()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b> Carico i due file come DataFrame </b> <i> poi unendoli in un unico DF tenendo come chiave d'unione l'index</i>. \n",
    "\\\n",
    "Vado quindi a pulire quel che é stato generato (una cartella) mantenendo solo quel che ci serve a noi: il file csv con i dati.\n",
    "\\\n",
    "Alla fine vado anche a cancellare fileWords.csv e fileTitles.csv in quanto non ci serviraranno piú e ci fará risparmiare spazio.\n",
    "\\\n",
    "\\\n",
    "<i> Attenzione: se esiste ancora una cartella di nome [merged_file](./merged_file), essa viene cancellata per evitare conflitti o errori. </i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if os.path.isdir(\"merged_file\"):\n",
    "    shutil.rmtree(\"merged_file\")\n",
    "\n",
    "titles_df = spark.read.csv(\"fileTitles.csv\", header=True, inferSchema=True)\n",
    "text_df = spark.read.csv(\"fileWords.csv\", header=True, inferSchema=True)\n",
    "\n",
    "merged_df = titles_df.join(text_df, \"index\")\n",
    "\n",
    "merged_df.coalesce(1).write.csv(\"merged_file\", header=True)\n",
    "\n",
    "for filename in os.listdir(\"merged_file\"):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        os.rename(os.path.join(\"merged_file\", filename), os.path.join(\"\", \"merged.csv\"))\n",
    "        shutil.rmtree(\"merged_file\")\n",
    "        \n",
    "os.remove(\"fileWords.csv\")\n",
    "os.remove(\"fileTitles.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora bisogna mappare le parole (contando quante ce ne sono) presenti in ogni cella del file CSV. Tiene conto quindi del titolo, la parola che é presente in quella pagina e quante volte viene utilizzata in quel titolo.\n",
    "\\\n",
    "Eliminiamo quindi il file [merged.csv](./merged.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"merged.csv\")\n",
    "df = df.select(\"title\", lower(\"text\").alias(\"text\"))\n",
    "\n",
    "words_df = df.select(\"title\", explode(split(regexp_replace(\"text\", r'\\W+', ' '), ' ')).alias(\"word\"))\n",
    "\n",
    "word_counts = words_df.groupBy(\"title\", \"word\").count().orderBy(\"count\", ascending=False)\n",
    "word_counts.write.csv(\"countedWordsDir\", mode=\"overwrite\", header=True)\n",
    "\n",
    "os.remove(\"merged.csv\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vado ad unire tutti i files CSV creati precedentemente eliminando quindi la cartella che li conteneva.\n",
    "\\\n",
    "Eliminiamo poi la cartella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = glob.glob(\"countedWordsDir/*.csv\")\n",
    "\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# unisco i dataframe in uno solo\n",
    "merged_df = pd.concat(dfs)\n",
    "\n",
    "merged_df.to_csv(\"countedWords.csv\", index=False)\n",
    "\n",
    "shutil.rmtree(\"countedWordsDir\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> <b>L’output deve contenere, per ogni parola, la lista di pagine di wikipedia\n",
    "che contengono quella parola</b>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quante volte sono state utilizzate le singole parole? Salviamo il risultato, poi, nel file [countedWordsFinalOutput.csv](./countedWordsFinalOutput.csv), unendo i file precedentemente generati separatamente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.format(\"csv\").option(\"header\", \"true\").load(\"countedWords.csv\")\n",
    "\n",
    "# raggruppa le righe in base alla colonna \"word\" e somma la colonna \"count\"\n",
    "sum_df = df.groupBy(\"word\").agg(sum(\"count\").alias(\"total_count\"))\n",
    "sum_df = sum_df.withColumn(\"total_count\", sum_df[\"total_count\"].cast(\"int\"))\n",
    "\n",
    "sum_df.write.mode(\"overwrite\").csv(\"paroleContate\", header=True)\n",
    "\n",
    "# unisco i file\n",
    "csv_files = glob.glob(\"paroleContate/*.csv\")\n",
    "\n",
    "dfs = []\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "merged_df = pd.concat(dfs)\n",
    "merged_df.to_csv(\"countedWordsFinalOutput.csv\", index=False)\n",
    "\n",
    "shutil.rmtree(\"paroleContate\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Elimino la colonna che ci é inutile (la colonna count) salvando il risultato su un ultimo file finale, da analizzare. Elimino poi il file [countedWords.csv](./countedWords.csv) che non ci servirá a nulla."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('countedWords.csv')\n",
    "df.drop('count', axis=1, inplace=True)\n",
    "df.to_csv('finalFileToAnalyze.csv', index=False)\n",
    "os.remove('countedWords.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Leggiamo tutte le parole presenti nella colonna \"word\" del file CSV. Utilizziamo un set in quanto non vogliamo che ci siano parole ripetute. Poi lo trasformiamo in una lista per renderlo indicizzabile e la trascriviamo in un file csv in modo da non dover eseguire ogni volta questa cella."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('finalFileToAnalyze.csv')\n",
    "word_list = []\n",
    "for row in df['word']:\n",
    "    words = re.findall(r'\\w+', str(row).lower())\n",
    "    word_list.extend(words)\n",
    "\n",
    "word_list = list(set(word_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ora controllo quali parole sono presenti nel file finale da controllare. Se le parole sono presenti, aggiungo il titolo ad una lista. Si creerá infine una riga in un file CSV con la parola e la lista di titoli.\n",
    "\\\n",
    "Eliminiamo [finalFileToAnalyze.csv](./finalFileToAnalyze.csv) in quanto inutile. Dovremmo utilizzare risults.csv per le analisi."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('finalFileToAnalyze.csv', newline='') as csv_file:\n",
    "    reader = csv.DictReader(csv_file)\n",
    "\n",
    "    # dizionario per mantenere le associazioni tra parole e titoli\n",
    "    word_title_dict = {}\n",
    "\n",
    "    for row in reader:\n",
    "        title = row['title']\n",
    "        word = row['word']\n",
    "\n",
    "        if word not in word_title_dict:\n",
    "            word_title_dict[word] = []\n",
    "\n",
    "        word_title_dict[word].append(title)\n",
    "\n",
    "with open('results.csv', mode='w', newline='') as csv_file:\n",
    "    writer = csv.writer(csv_file)\n",
    "\n",
    "    # header\n",
    "    writer.writerow(['word', 'titles'])\n",
    "\n",
    "    for word in word_list:\n",
    "        if word in word_title_dict:\n",
    "            titles = word_title_dict[word]\n",
    "        else:\n",
    "            titles = []\n",
    "\n",
    "        writer.writerow([word, titles])\n",
    "os.remove(\"finalFileToAnalyze.csv\")\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "<h1>Grafici e statistiche</h1>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Genero delle statistiche sui dati usando il file [countedWordsFinalOutput.csv](./countedWordsFinalOutput.csv)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = pd.read_csv('countedWordsFinalOutput.csv', header=0)\n",
    "ordered = temp_df.sort_values(by=['total_count'], ascending=False)\n",
    "print(ordered.head(20).describe())\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafico a barre che tiene conto del numero di titoli per ogni parola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('countedWordsFinalOutput.csv')\n",
    "data = data.sort_values(by=['total_count'], ascending=False)\n",
    "data = data.head(10)\n",
    "x = data['word']\n",
    "y = data['total_count']\n",
    "\n",
    "plt.bar(x, y)\n",
    "plt.title('Parole piú utilizzate')\n",
    "plt.xlabel('Parola')\n",
    "plt.ylabel('Counter')\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creazione di un grafico che dimostra quale parola viene utilizzata in piú titoli.\n",
    "\\\n",
    "Utilizza lo split per dividere le varie parole contenute nella colonna \"titles\" visto che sono divise da una virgola."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results.csv')\n",
    "\n",
    "# creazione di una nuova colonna \"num_titles\" che conta il numero di titoli in \"titles\"\n",
    "df['num_titles'] = df['titles'].str.split(',').apply(lambda x: len(x))\n",
    "\n",
    "df_sorted = df.sort_values('num_titles', ascending=False)\n",
    "\n",
    "colori = ['red', 'blue', 'green', 'orange', 'purple']\n",
    "df_words = []\n",
    "df_counts = []\n",
    "# stampa dei primi 10 record con le parole della stessa riga\n",
    "for i in range(10):\n",
    "    row = df_sorted.iloc[i]\n",
    "    df_words.append(row['word'])\n",
    "    df_counts.append(row['num_titles'])\n",
    "    \n",
    "x = df_words\n",
    "y = df_counts\n",
    "plt.bar(x, y, color = colori)\n",
    "plt.title('Parole presenti in piú titoli')\n",
    "plt.xlabel('Parola')\n",
    "plt.ylabel('Counter')\n",
    "plt.xticks(\n",
    "    rotation=90, \n",
    "    horizontalalignment='right',\n",
    "    fontweight='normal',\n",
    "    fontsize='large'  \n",
    ")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creo un file csv contenente le parole e il numero di titoli (la dimensione delle liste di ogni parola)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results.csv')\n",
    "\n",
    "# crea una nuova colonna con la grandezza della lista\n",
    "df['list_size'] = df['titles'].apply(lambda x: len(x.split(',')))\n",
    "\n",
    "# crea un nuovo df con le colonne \"word\" e \"list_size\"\n",
    "new_df = df[['word', 'list_size']].copy()\n",
    "\n",
    "new_df.to_csv('titlesSize.csv', index=False)\n",
    "\n",
    "df = pd.read_csv(\"titlesSize.csv\")\n",
    "\n",
    "# crea un nuovo df con il conteggio delle occorrenze per ogni valore di list_size\n",
    "counts = df.groupby('list_size').size().reset_index(name='occurrences')\n",
    "\n",
    "counts.to_csv(\"occurrences.csv\", index=False)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crea il grafico analizzando i dati contenuti nel file csv creato sopra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = []\n",
    "df_occs = []\n",
    "\n",
    "data = pd.read_csv('occurrences.csv')\n",
    "data = data.head(50)\n",
    "x = data['list_size']\n",
    "y = data['occurrences']\n",
    "\n",
    "plt.plot(x,y)\n",
    "plt.ticklabel_format(style='sci', axis='y', scilimits=(0,0), useMathText=True)\n",
    "\n",
    "plt.xlabel('Titoli contenenti n parole')\n",
    "plt.ylabel('Occorrenze')\n",
    "plt.title('Numero di titoli che contengono n parole')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Grafico che tiene conto dei (n) titoli per singola parola. Se ad esempio, ci sono 5 parole che contengono 1 titolo, nell'asse x rappresenteremo il numero di parole per titolo. Nell'asse y invece il numero di titoli che contengono quelle n parole. Teniamo conto dei primi 5."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_titles = []\n",
    "df_occs = []\n",
    "\n",
    "data = pd.read_csv('occurrences.csv')\n",
    "data = data.head(5)\n",
    "x = data['list_size']\n",
    "y = data['occurrences']\n",
    "\n",
    "fig, plot = plt.subplots()\n",
    "\n",
    "plot.plot(x, y)\n",
    "\n",
    "# formatta l'asse x\n",
    "plot.xaxis.set_major_locator(mtick.MaxNLocator(integer=True))\n",
    "\n",
    "# formatta l'asse y\n",
    "fmt = '{x:,.0f}'\n",
    "tick = mtick.StrMethodFormatter(fmt)\n",
    "plot.yaxis.set_major_formatter(tick)\n",
    "\n",
    "plt.xlabel('Titoli contenenti n parole')\n",
    "plt.ylabel('Occorrenze')\n",
    "plt.title('Numero di titoli che contengono n parole (primi 5 valori)')\n",
    "plt.show()\n",
    "shutil.rmtree(\"occurrences.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
